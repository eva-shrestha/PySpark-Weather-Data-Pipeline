{"cells":[{"cell_type":"code","source":["import requests\nimport uuid\nfrom datetime import datetime\nfrom pyspark.sql.functions import col, lit, to_timestamp,udf, explode,from_unixtime\nfrom pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType, TimestampType, ArrayType\nfrom delta.tables import *"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4c6f07e2-e25b-4f18-8381-0b810c2a5cde","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["spark.catalog.clearCache()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1e4c5fd3-ef76-45fe-8403-08a052dc98fa","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\nDROP TABLE IF EXISTS data_log_table"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000,"implicitDf":true},"nuid":"ab18af06-d6fb-4934-9fef-66d62c8c8498","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.rm(\"/user/hive/warehouse/data_log_table\", recurse=True)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"ccedddec-ebbd-42cb-86fa-0039441d47cc","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["%sql\nCREATE OR REPLACE TABLE data_log_table (\n  id STRING,\n  load_type STRING,\n  table_name STRING,\n  process_start_time TIMESTAMP,\n  process_end_time TIMESTAMP,\n  status STRING,\n  comments STRING,\n  start_date_time TIMESTAMP,\n  end_date_time TIMESTAMP,\n  created_on TIMESTAMP,\n  created_by STRING\n)\nUSING DELTA;\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000,"implicitDf":true},"nuid":"6b5df0da-fdb2-4daa-922e-bc338ab9ae33","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def logs(func):\n    def wrapper(*args, **kwargs):\n        id = str(uuid.uuid4())\n        load_type = args[0]\n        table_name = args[1]\n        process_start_dt = datetime.now()\n        name = 'Eva Shrestha'\n\n        spark.sql(f\"INSERT INTO data_log_table (id, load_type, table_name, process_start_time, status, created_on, created_by) \\\n            VALUES ('{id}', '{load_type}', '{table_name}', '{process_start_dt}', 'EXTRACTING', '{process_start_dt}', '{name}')\")\n\n\n        df, start, end = func(*args[2:], **kwargs)\n\n        df = df.withColumn('load_run_id', lit(id))\n        df = df.withColumn('created_on', lit(process_start_dt).cast(TimestampType()))\n        df = df.withColumn('created_by', lit(name))\n\n        df.write.format('delta').mode('append').saveAsTable(table_name)\n\n        process_end_dt = datetime.now()\n        spark.sql(f\"UPDATE data_log_table SET process_end_time = '{process_end_dt}', status='COMPLETED', start_date_time='{start}', end_date_time='{end}' WHERE id='{id}'\")\n\n        return df\n\n    return wrapper"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"fadd2705-5b72-4483-9a76-f74c1b085fd6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Logger","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":2485622306277368,"dataframes":["_sqldf"]}},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
